{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"test_model2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.7.6 64-bit","metadata":{"interpreter":{"hash":"5d93a29d48a24f34d819daa2e282f417b169645e8ec887fbefb99181c4626a16"}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"kE8loR2oTBxm"},"source":["Reference: \n","1. SpinalNet: Deep Neural Network with Gradual Input\n","2. https://github.com/dipuk0506/SpinalNet"]},{"cell_type":"markdown","metadata":{"id":"4RvfKMj4hgsO"},"source":["# 1.0 Read test image "]},{"cell_type":"code","metadata":{"id":"0bsngCBb-FRX","colab":{"background_save":true}},"source":["import numpy as np\n","import pandas as pd\n","import zipfile\n","from google.colab import drive\n","\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r10PVyjB-S-7"},"source":["import torchvision\n","from torchvision import transforms\n","import torch.utils.data as data\n","from PIL import ImageFile\n","\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","batch_size_test = 64\n","\n","TRANSFORM_IMG = transforms.Compose([transforms.Resize((240, 320)), transforms.ToTensor()])\n","\n","TEST_DATA_PATH = \"/content/drive/My Drive/TDS3651 Visual Information Processing/project/dataset/regression/test/\"\n","test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=TRANSFORM_IMG)\n","test_data_loader = data.DataLoader(test_data, batch_size=batch_size_test, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dlUIiX8oi-1T"},"source":["# 2.0 Test Model"]},{"cell_type":"code","metadata":{"id":"0-0l5V2B-ao8"},"source":["# regression\n","# first_HL = 50\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchsummary import summary\n","\n","torch.backends.cudnn.enabled = False\n","\n","first_HL = 50\n","\n","class Net_R(nn.Module):\n","\n","  def __init__(self):\n","      super(Net_R, self).__init__()\n","      # kernal 5, maxpooling = 2\n","      self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n","      self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","      self.conv2_drop = nn.Dropout2d()\n","      # features shape = 20*57*77\n","      self.lru = nn.LeakyReLU()\n","      self.fc1 = nn.Linear(int((20*57*77)/2), first_HL)  \n","      self.fc2 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)  \n","      self.fc3 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL) \n","      self.fc4 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)  \n","      self.fc5 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)  \n","      self.fc6 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)  \n","      self.fcx = nn.Linear(first_HL*6, 1) \n","        \n","\n","  def forward(self, x):\n","    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","    x = x.view(-1, 20*57*77)\n","    x1 = x[:, 0:int((20*57*77)/2)]\n","    \n","    x1 = self.lru(self.fc1(x1))\n","    x2 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x1], dim=1)\n","    x2 = self.lru(self.fc2(x2))\n","    x3 = torch.cat([ x[:,0:int((20*57*77)/2)], x2], dim=1)\n","    x3 = self.lru(self.fc3(x3))\n","    x4 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x3], dim=1)\n","    x4 = self.lru(self.fc4(x4))\n","    x5 = torch.cat([ x[:,0:int((20*57*77)/2)], x4], dim=1)\n","    x5 = self.lru(self.fc3(x5))\n","    x6 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x5], dim=1)\n","    x6 = self.lru(self.fc4(x6))\n","\n","    # before fc2  \n","    x = torch.cat([x1, x2], dim=1)\n","    x = torch.cat([x, x3], dim=1)\n","    x = torch.cat([x, x4], dim=1)\n","    x = torch.cat([x, x5], dim=1)\n","    x = torch.cat([x, x6], dim=1)\n","\n","    # fc2\n","    x = self.fcx(x)\n","\n","    return x\n","\n","\n","# model= Net_R()\n","# model.cuda()\n","# summary(model, (3, 240, 320))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"moxV_1f7-b_b"},"source":["from sklearn.metrics import mean_squared_error\n","from math import sqrt\n","\n","def cal_rmse(y_predicted, target):\n","  rmse = sqrt(mean_squared_error(target, y_predicted))\n","  return rmse"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uhA0enVA-eAD","outputId":"f3d94a4d-5ce1-4de3-bbbf-c3587841f7a4","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import os\n","import torch\n","from itertools import chain\n","import shutil\n","\n","folder = '/content/drive/My Drive/TDS3651 Visual Information Processing/project/dataset/regression/model2'\n","tested_result = pd.DataFrame(columns = ['model', 'epoch', 'rmse'])\n","\n","model = Net_R()\n","\n","for filename in os.listdir(folder):\n","  print(filename)\n","  name = '/content/drive/My Drive/TDS3651 Visual Information Processing/project/dataset/regression/model2/' + str(filename)\n","  model = torch.load(name)\n","  model.eval()\n","  predicted = []\n","  actual = []\n","    \n","  for data,target in test_data_loader:\n","    model.eval()\n","    output = model(data.type(torch.cuda.FloatTensor))\n","    predicted.append(output.view(len(output)).cpu().data.numpy())\n","    actual.append(target.cpu().data.numpy())\n","\n","  loss_rmse = cal_rmse(list(chain.from_iterable(predicted)), list(chain.from_iterable(actual)))\n","\n","  name = filename.split('.')[0]\n","  name = name.split('_')\n","  model_name = name[0]\n","  epoch = name[2]\n","  print(model_name)  \n","  print(epoch) \n","\n","  tested_result.loc[len(tested_result)] = [model_name, epoch, loss_rmse]\n","  print(tested_result)  \n","\n","  filename = 'tested_result_' + str(model_name) + '_' +str(epoch)+ '.csv'\n","  tested_result.to_csv(filename, encoding='utf-8', index=False)\n","  shutil.move('/content/drive/My Drive/TDS3651 Visual Information Processing/project/' + filename, folder)"],"execution_count":1,"outputs":[]}]}