{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_model1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXaaYqL5S651"
      },
      "source": [
        "Reference: \n",
        "1. SpinalNet: Deep Neural Network with Gradual Input\n",
        "2. https://github.com/dipuk0506/SpinalNet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGPAw2mjXpxG"
      },
      "source": [
        "# 1.0 Read train image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOu1M2gue3MX"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "\n",
        "batch_size_train = 64\n",
        "\n",
        "TRANSFORM_IMG = transforms.Compose([transforms.Resize((240, 320)), transforms.ToTensor()])\n",
        "\n",
        "# load images in batches\n",
        "TRAIN_DATA_PATH = \"classification/train/\"\n",
        "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
        "train_data_loader = data.DataLoader(train_data, batch_size=batch_size_train, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EYPN0xsgzvV"
      },
      "source": [
        "# 2.0 Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YLLqS7efDW8"
      },
      "source": [
        "# classification\n",
        "# first_HL = 8\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "torch.backends.cudnn.enabled = False\n",
        "\n",
        "first_HL = 8\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(Net, self).__init__()\n",
        "      # kernal 5x5, maxpooling = 2x2\n",
        "      self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "      self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "      self.conv2_drop = nn.Dropout2d()\n",
        "      # features shape = 20*57*77\n",
        "      self.fc1 = nn.Linear(int((20*57*77)/2), first_HL) \n",
        "      self.fc1_1 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)\n",
        "      self.fc1_2 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)\n",
        "      self.fc1_3 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL) \n",
        "      self.fc1_4 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)\n",
        "      self.fc1_5 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)\n",
        "      self.fc2 = nn.Linear(first_HL*6, 70) \n",
        "        \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 20*57*77)\n",
        "    x1 = x[:, 0:int((20*57*77)/2)]\n",
        "    \n",
        "    x1 = F.relu(self.fc1(x1))\n",
        "    x2 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x1], dim=1)\n",
        "    x2 = F.relu(self.fc1_1(x2))\n",
        "    x3 = torch.cat([ x[:,0:int((20*57*77)/2)], x2], dim=1)\n",
        "    x3 = F.relu(self.fc1_2(x3))\n",
        "    x4 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x3], dim=1)\n",
        "    x4 = F.relu(self.fc1_3(x4))\n",
        "    x5 = torch.cat([ x[:,0:int((20*57*77)/2)], x4], dim=1)\n",
        "    x5 = F.relu(self.fc1_4(x5))\n",
        "    x6 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x5], dim=1)\n",
        "    x6 = F.relu(self.fc1_5(x6))\n",
        "\n",
        "    # before fc2  \n",
        "    x = torch.cat([x1, x2], dim=1)\n",
        "    x = torch.cat([x, x3], dim=1)\n",
        "    x = torch.cat([x, x4], dim=1)\n",
        "    x = torch.cat([x, x5], dim=1)\n",
        "    x = torch.cat([x, x6], dim=1)\n",
        "\n",
        "    # fc2\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVBkL7F6e46G"
      },
      "source": [
        "# model1: learning_rate = 0.01, momentum = 0.5\n",
        "# training\n",
        "\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from math import sqrt\n",
        "\n",
        "n_epochs = 8\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        " \n",
        "torch.backends.cudnn.enabled = False\n",
        "\n",
        "model1= Net()\n",
        "optimizer = optim.SGD(model1.parameters(), lr=learning_rate, momentum=momentum)\n",
        "result = pd.DataFrame(columns = ['epoch', 'train_losses'])\n",
        "\n",
        "for i in range(1, n_epochs+1):\n",
        "  for batch_idx, (data, target) in enumerate(train_data_loader):\n",
        "    output = model1(data)\n",
        "    loss = F.nll_loss(output, target, reduction='mean')\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  joblib_file = 'model1_epoch_' + str(i) + '.pt'\n",
        "  torch.save(model1, joblib_file)\n",
        "  shutil.move(os.getcwd() + '\\\\' + joblib_file, os.getcwd() + '\\\\newClassification')\n",
        "\n",
        "  \n",
        "  result.loc[len(result)] = [i, loss.item()]\n",
        "  filename = 'model_result_' + str(i) + '.csv'\n",
        "  result.to_csv(filename, encoding='utf-8', index=False)\n",
        "  shutil.move(os.getcwd() + '\\\\' + filename, os.getcwd() + '\\\\newClassification')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}