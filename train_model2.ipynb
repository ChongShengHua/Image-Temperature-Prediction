{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.6 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "5d93a29d48a24f34d819daa2e282f417b169645e8ec887fbefb99181c4626a16"
        }
      }
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    },
    "colab": {
      "name": "train_model2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S6N0CMfS5bY"
      },
      "source": [
        "Reference: \n",
        "1. SpinalNet: Deep Neural Network with Gradual Input\n",
        "2. https://github.com/dipuk0506/SpinalNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ9av-y1huTV"
      },
      "source": [
        "# 1.0 Read test image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvqg27oqS0gS"
      },
      "source": [
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.utils.data as data\n",
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "batch_size_train = 64\n",
        "\n",
        "TRANSFORM_IMG = transforms.Compose([transforms.Resize((240, 320)), transforms.ToTensor()])\n",
        "\n",
        "# load images in batches\n",
        "TRAIN_DATA_PATH = \"regression/train/\"\n",
        "train_data = torchvision.datasets.ImageFolder(root=TRAIN_DATA_PATH, transform=TRANSFORM_IMG)\n",
        "train_data_loader = data.DataLoader(train_data, batch_size=batch_size_train, shuffle=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xEv9EZoh9rC"
      },
      "source": [
        "# 2.0 Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej6w2X8mS0gY"
      },
      "source": [
        "# model: regression\n",
        "# first_HL = 50\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "torch.backends.cudnn.enabled = False\n",
        "\n",
        "first_HL = 50\n",
        "\n",
        "class Net_R(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "      super(Net_R, self).__init__()\n",
        "      # kernal 5, maxpooling = 2\n",
        "      self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n",
        "      self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "      self.conv2_drop = nn.Dropout2d()\n",
        "      # features shape = 20*57*77\n",
        "      self.lru = nn.LeakyReLU()\n",
        "      self.fc1 = nn.Linear(int((20*57*77)/2), first_HL) \n",
        "      self.fc2 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL) \n",
        "      self.fc3 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL) \n",
        "      self.fc4 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL) \n",
        "      self.fc5 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL) \n",
        "      self.fc6 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL) \n",
        "      self.fcx = nn.Linear(first_HL*6, 1)\n",
        "        \n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 20*57*77)\n",
        "    x1 = x[:, 0:int((20*57*77)/2)]\n",
        "    \n",
        "    x1 = self.lru(self.fc1(x1))\n",
        "    x2 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x1], dim=1)\n",
        "    x2 = self.lru(self.fc2(x2))\n",
        "    x3 = torch.cat([ x[:,0:int((20*57*77)/2)], x2], dim=1)\n",
        "    x3 = self.lru(self.fc3(x3))\n",
        "    x4 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x3], dim=1)\n",
        "    x4 = self.lru(self.fc4(x4))\n",
        "    x5 = torch.cat([ x[:,0:int((20*57*77)/2)], x4], dim=1)\n",
        "    x5 = self.lru(self.fc3(x5))\n",
        "    x6 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x5], dim=1)\n",
        "    x6 = self.lru(self.fc4(x6))\n",
        "\n",
        "    # before fc2\n",
        "    x = torch.cat([x1, x2], dim=1)\n",
        "    x = torch.cat([x, x3], dim=1)\n",
        "    x = torch.cat([x, x4], dim=1)\n",
        "    x = torch.cat([x, x5], dim=1)\n",
        "    x = torch.cat([x, x6], dim=1)\n",
        "\n",
        "    # fc2\n",
        "    x = self.fcx(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbh_tvwIS0gg",
        "outputId": "a96f686e-ffbe-4ad9-c571-9fd56be45adb"
      },
      "source": [
        "# model2: learning_rate = 0.01\n",
        "# training\n",
        "\n",
        "from math import sqrt\n",
        "import pandas as pd\n",
        "import shutil\n",
        "\n",
        "model2 = Net_R()\n",
        "model2.cuda()\n",
        "optimizer = torch.optim.Adam(model2.parameters(), lr=0.01)\n",
        "loss_func = torch.nn.MSELoss()\n",
        "EPOCH = 100\n",
        "result = pd.DataFrame(columns = ['epoch', 'train_loss'])\n",
        "\n",
        "for i in range(1, EPOCH+1):\n",
        "  for batch_idx, (data, target) in enumerate(train_data_loader):\n",
        "    data, target = data.cuda(), target.cuda()\n",
        "    output = model2(data)\n",
        "    loss = loss_func(output, target.type(torch.cuda.FloatTensor)) \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(batch_idx)\n",
        "    print(loss.item())\n",
        "\n",
        "  joblib_file = 'model2_epoch_' + str(i) + '.pt'\n",
        "  torch.save(model2, joblib_file)\n",
        "    \n",
        "  shutil.move(os.getcwd() + '\\\\' + joblib_file, os.getcwd() + '\\\\newRegression')\n",
        "  \n",
        "  result.loc[len(result)] = [i, sqrt(loss.item())]\n",
        "  filename = 'model2_result_' + str(i) + '.csv'\n",
        "  result.to_csv(filename, encoding='utf-8', index=False)"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}