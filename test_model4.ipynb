{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"test_model4.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"L722gLfiS88C"},"source":["Reference: \n","1. SpinalNet: Deep Neural Network with Gradual Input\n","2. https://github.com/dipuk0506/SpinalNet\n"]},{"cell_type":"markdown","metadata":{"id":"h3RsABf2l5kd"},"source":["# 1.0 Read test image "]},{"cell_type":"code","metadata":{"id":"v5NpI6qTS09I"},"source":["import torchvision\n","from torchvision import transforms\n","import torch.utils.data as data\n","from PIL import ImageFile\n","\n","ImageFile.LOAD_TRUNCATED_IMAGES = True\n","\n","batch_size_test = 64\n","\n","TRANSFORM_IMG = transforms.Compose([transforms.Resize((240, 320)), transforms.ToTensor()])\n","\n","TEST_DATA_PATH = \"/content/drive/My Drive/TDS3651 Visual Information Processing/project/dataset/regression/test/\"\n","test_data = torchvision.datasets.ImageFolder(root=TEST_DATA_PATH, transform=TRANSFORM_IMG)\n","test_data_loader = data.DataLoader(test_data, batch_size=batch_size_test, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PEOpTHhql2zr"},"source":["# 2.0 Test Model"]},{"cell_type":"code","metadata":{"id":"7zC3SPxqS09L"},"source":["# regression\n","# first_HL = 50\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchsummary import summary\n","\n","torch.backends.cudnn.enabled = False\n","\n","first_HL = 50\n","\n","class Net_R(nn.Module):\n","\n","    def __init__(self):\n","        super(Net_R, self).__init__()\n","        # kernal 5, maxpooling = 2\n","        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n","        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n","        self.conv2_drop = nn.Dropout2d()\n","        # features shape = 20*57*77\n","        self.lru = nn.LeakyReLU()\n","        self.fc1 = nn.Linear(int((20*57*77)/2), first_HL)  \n","        self.fc2 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)  \n","        self.fc3 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)  \n","        self.fc4 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)  \n","        self.fc5 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL)  \n","        self.fc6 = nn.Linear(int((20*57*77)/2) + first_HL, first_HL) \n","        self.fcx = nn.Linear(first_HL*6, 1) \n","        \n","\n","    def forward(self, x):\n","        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n","        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n","        x = x.view(-1, 20*57*77)\n","        x1 = x[:, 0:int((20*57*77)/2)]\n","\n","        x1 = self.lru(self.fc1(x1))\n","        x2 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x1], dim=1)\n","        x2 = self.lru(self.fc2(x2))\n","        x3 = torch.cat([ x[:,0:int((20*57*77)/2)], x2], dim=1)\n","        x3 = self.lru(self.fc3(x3))\n","        x4 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x3], dim=1)\n","        x4 = self.lru(self.fc4(x4))\n","        x5 = torch.cat([ x[:,0:int((20*57*77)/2)], x4], dim=1)\n","        x5 = self.lru(self.fc3(x5))\n","        x6 = torch.cat([ x[:,int((20*57*77)/2):20*57*77], x5], dim=1)\n","        x6 = self.lru(self.fc4(x6))\n","\n","        # before fc2  \n","        x = torch.cat([x1, x2], dim=1)\n","        x = torch.cat([x, x3], dim=1)\n","        x = torch.cat([x, x4], dim=1)\n","        x = torch.cat([x, x5], dim=1)\n","        x = torch.cat([x, x6], dim=1)\n","\n","        # fc2\n","        x = self.fcx(x)\n","\n","        return x\n","\n","\n","# model= Net()\n","# model.cuda()\n","# summary(model, (3, 240, 320))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HB8O8sjS09N"},"source":["import os\n","import torch\n","from itertools import chain\n","\n","folder = '/content/drive/My Drive/TDS3651 Visual Information Processing/project/dataset/regression/model4'\n","tested_result = pd.DataFrame(columns = ['model', 'epoch', 'rmse'])\n","\n","model = Net_R()\n","model.cuda()\n","\n","for filename in os.listdir(folder):\n","    print(filename)\n","    model = torch.load(folder+'\\\\'+ filename)\n","    model.eval()\n","    predicted = []\n","    actual = []\n","    \n","    for data,target in test_data_loader:\n","        data, target = data.cuda(), target.cuda()\n","        model.eval()\n","        output = model(data.type(torch.cuda.FloatTensor))\n","        predicted.append(output.view(len(output)).cpu().data.numpy())\n","        actual.append(target.cpu().data.numpy())\n","\n","    loss_rmse = cal_rmse(list(chain.from_iterable(predicted)), list(chain.from_iterable(actual)))\n","\n","    name = filename.split('.')[0]\n","    name = name.split('_')\n","    model_name = name[0]\n","    epoch = name[2]\n","    print(model_name)  \n","    print(epoch)  \n","\n","    tested_result.loc[len(tested_result)] = [model_name, epoch, loss_rmse]\n","    print(tested_result)  \n","\n","    filename = 'tested_result_' + str(model_name) + '_' +str(epoch)+ '.csv'\n","    tested_result.to_csv(filename, encoding='utf-8', index=False)\n","    "],"execution_count":null,"outputs":[]}]}